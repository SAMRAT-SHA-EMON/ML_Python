{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "eb0ab538",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.          1.         -1.          0.66666667]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "def newton_interpolation(x, y):\n",
    "    n = len(x)\n",
    "    F = np.zeros((n, n))\n",
    "\n",
    "    F[:,0] = y\n",
    "\n",
    "    for j in range(1, n):\n",
    "        for i in range(n-j):\n",
    "            F[i][j] = (F[i+1][j-1] - F[i][j-1]) / (x[i+j] - x[i])\n",
    "\n",
    "    return F[0]\n",
    "\n",
    "# Example usage\n",
    "x_data = np.array([1, 2, 3, 4])\n",
    "y_data = np.array([0, 1, 0, 1])\n",
    "\n",
    "coefficients = newton_interpolation(x_data, y_data)\n",
    "print(coefficients)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "65632f98",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.2 0.4 0.6 0.8]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "def machine_learning_interpolation(x, y):\n",
    "    model = LinearRegression().fit(x.reshape(-1, 1), y)\n",
    "    interpolated_values = model.predict(x.reshape(-1, 1))\n",
    "    return interpolated_values\n",
    "\n",
    "# Example usage\n",
    "x_data = np.array([1, 2, 3, 4])\n",
    "y_data = np.array([0, 1, 0, 1])\n",
    "\n",
    "interpolated_values = machine_learning_interpolation(x_data, y_data)\n",
    "print(interpolated_values)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9e0d958e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from ga import GeneticAlgorithm\n",
    "\n",
    "# def objective_function(x):\n",
    "#     return x**2 - 4*x + 4  # Example objective function\n",
    "\n",
    "# ga = GeneticAlgorithm(objective_function, population_size=50, generations=100)\n",
    "# result = ga.run()\n",
    "# print(result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "987d9cea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# class CustomGeneticAlgorithm(GeneticAlgorithm):\n",
    "#     def custom_crossover(self, parent1, parent2):\n",
    "#         # Implement custom crossover logic\n",
    "#         pass\n",
    "\n",
    "#     def custom_mutation(self, individual):\n",
    "#         # Implement custom mutation logic\n",
    "#         pass\n",
    "\n",
    "# # Example usage\n",
    "# custom_ga = CustomGeneticAlgorithm(objective_function, population_size=50, generations=100)\n",
    "# result_custom = custom_ga.run()\n",
    "# print(result_custom)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "56b2a121",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\MONIRUL ISLAM\\AppData\\Roaming\\Python\\Python311\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\MONIRUL ISLAM\\AppData\\Roaming\\Python\\Python311\\site-packages\\keras\\src\\backend.py:873: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\MONIRUL ISLAM\\AppData\\Roaming\\Python\\Python311\\site-packages\\keras\\src\\optimizers\\__init__.py:309: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "Epoch 1/100\n",
      "WARNING:tensorflow:From C:\\Users\\MONIRUL ISLAM\\AppData\\Roaming\\Python\\Python311\\site-packages\\keras\\src\\utils\\tf_utils.py:492: The name tf.ragged.RaggedTensorValue is deprecated. Please use tf.compat.v1.ragged.RaggedTensorValue instead.\n",
      "\n",
      "1/1 [==============================] - 1s 662ms/step - loss: 28.6041\n",
      "Epoch 2/100\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 27.4508\n",
      "Epoch 3/100\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 26.3743\n",
      "Epoch 4/100\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 25.3585\n",
      "Epoch 5/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 24.3620\n",
      "Epoch 6/100\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 23.4058\n",
      "Epoch 7/100\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 22.5004\n",
      "Epoch 8/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 21.6417\n",
      "Epoch 9/100\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 20.8129\n",
      "Epoch 10/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 20.0185\n",
      "Epoch 11/100\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 19.2358\n",
      "Epoch 12/100\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 18.4651\n",
      "Epoch 13/100\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 17.7076\n",
      "Epoch 14/100\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 16.9636\n",
      "Epoch 15/100\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 16.2409\n",
      "Epoch 16/100\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 15.5415\n",
      "Epoch 17/100\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 14.8549\n",
      "Epoch 18/100\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 14.1881\n",
      "Epoch 19/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 13.5567\n",
      "Epoch 20/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 12.9476\n",
      "Epoch 21/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 12.3505\n",
      "Epoch 22/100\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 11.7616\n",
      "Epoch 23/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 11.1827\n",
      "Epoch 24/100\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 10.6169\n",
      "Epoch 25/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 10.0598\n",
      "Epoch 26/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 9.5119\n",
      "Epoch 27/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 8.9739\n",
      "Epoch 28/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 8.4466\n",
      "Epoch 29/100\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 7.9309\n",
      "Epoch 30/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 7.4272\n",
      "Epoch 31/100\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 6.9360\n",
      "Epoch 32/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 6.4580\n",
      "Epoch 33/100\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 5.9949\n",
      "Epoch 34/100\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 5.5470\n",
      "Epoch 35/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 5.1170\n",
      "Epoch 36/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 4.7077\n",
      "Epoch 37/100\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 4.3150\n",
      "Epoch 38/100\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 3.9386\n",
      "Epoch 39/100\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 3.5790\n",
      "Epoch 40/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 3.2364\n",
      "Epoch 41/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 2.9116\n",
      "Epoch 42/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 2.6061\n",
      "Epoch 43/100\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 2.3205\n",
      "Epoch 44/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 2.0581\n",
      "Epoch 45/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1.8144\n",
      "Epoch 46/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1.5885\n",
      "Epoch 47/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.3803\n",
      "Epoch 48/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1.1897\n",
      "Epoch 49/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1.0167\n",
      "Epoch 50/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.8608\n",
      "Epoch 51/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.7216\n",
      "Epoch 52/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.5986\n",
      "Epoch 53/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.4913\n",
      "Epoch 54/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.3988\n",
      "Epoch 55/100\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.3202\n",
      "Epoch 56/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.2546\n",
      "Epoch 57/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.2012\n",
      "Epoch 58/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.1587\n",
      "Epoch 59/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.1263\n",
      "Epoch 60/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.1020\n",
      "Epoch 61/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.0854\n",
      "Epoch 62/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0751\n",
      "Epoch 63/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0698\n",
      "Epoch 64/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.0685\n",
      "Epoch 65/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0701\n",
      "Epoch 66/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0738\n",
      "Epoch 67/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.0787\n",
      "Epoch 68/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0839\n",
      "Epoch 69/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.0888\n",
      "Epoch 70/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.0929\n",
      "Epoch 71/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0961\n",
      "Epoch 72/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.0981\n",
      "Epoch 73/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.0990\n",
      "Epoch 74/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0987\n",
      "Epoch 75/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0974\n",
      "Epoch 76/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.0953\n",
      "Epoch 77/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0925\n",
      "Epoch 78/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0893\n",
      "Epoch 79/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.0858\n",
      "Epoch 80/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.0822\n",
      "Epoch 81/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0787\n",
      "Epoch 82/100\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.0754\n",
      "Epoch 83/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0725\n",
      "Epoch 84/100\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.0701\n",
      "Epoch 85/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0680\n",
      "Epoch 86/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.0665\n",
      "Epoch 87/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.0654\n",
      "Epoch 88/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0648\n",
      "Epoch 89/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0644\n",
      "Epoch 90/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.0644\n",
      "Epoch 91/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0645\n",
      "Epoch 92/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 5ms/step - loss: 0.0647\n",
      "Epoch 93/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0650\n",
      "Epoch 94/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0652\n",
      "Epoch 95/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0653\n",
      "Epoch 96/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.0652\n",
      "Epoch 97/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0651\n",
      "Epoch 98/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0648\n",
      "Epoch 99/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0644\n",
      "Epoch 100/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0639\n",
      "1/1 [==============================] - 0s 97ms/step\n",
      "[[9.494316]]\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "\n",
    "def create_neural_network():\n",
    "    model = models.Sequential([\n",
    "        layers.Dense(64, activation='relu', input_shape=(1,)),\n",
    "        layers.Dense(64, activation='relu'),\n",
    "        layers.Dense(1)\n",
    "    ])\n",
    "    model.compile(optimizer='adam', loss='mean_squared_error')\n",
    "    return model\n",
    "\n",
    "# Example usage\n",
    "x_data = np.array([1, 2, 3, 4])\n",
    "y_data = np.array([2, 4, 6, 8])\n",
    "\n",
    "model = create_neural_network()\n",
    "model.fit(x_data, y_data, epochs=100)\n",
    "\n",
    "result = model.predict([5])\n",
    "print(result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f632cc12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: scikit-learn in c:\\programdata\\anaconda3\\lib\\site-packages (1.3.0)\n",
      "Requirement already satisfied: numpy>=1.17.3 in c:\\programdata\\anaconda3\\lib\\site-packages (from scikit-learn) (1.24.3)\n",
      "Requirement already satisfied: scipy>=1.5.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from scikit-learn) (1.11.1)\n",
      "Requirement already satisfied: joblib>=1.1.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from scikit-learn) (1.2.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from scikit-learn) (2.2.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f5624afa",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Invalid parameter 'optimizer' for estimator MLPRegressor(hidden_layer_sizes=(32,), max_iter=50). Valid parameters are: ['activation', 'alpha', 'batch_size', 'beta_1', 'beta_2', 'early_stopping', 'epsilon', 'hidden_layer_sizes', 'learning_rate', 'learning_rate_init', 'max_fun', 'max_iter', 'momentum', 'n_iter_no_change', 'nesterovs_momentum', 'power_t', 'random_state', 'shuffle', 'solver', 'tol', 'validation_fraction', 'verbose', 'warm_start'].",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[7], line 15\u001b[0m\n\u001b[0;32m     13\u001b[0m nn_model \u001b[38;5;241m=\u001b[39m MLPRegressor()\n\u001b[0;32m     14\u001b[0m grid_search \u001b[38;5;241m=\u001b[39m GridSearchCV(nn_model, param_grid, cv\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m3\u001b[39m)\n\u001b[1;32m---> 15\u001b[0m grid_search\u001b[38;5;241m.\u001b[39mfit(x_data\u001b[38;5;241m.\u001b[39mreshape(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m1\u001b[39m), y_data)\n\u001b[0;32m     17\u001b[0m best_model \u001b[38;5;241m=\u001b[39m grid_search\u001b[38;5;241m.\u001b[39mbest_estimator_\n\u001b[0;32m     18\u001b[0m result_tuned \u001b[38;5;241m=\u001b[39m best_model\u001b[38;5;241m.\u001b[39mpredict([[\u001b[38;5;241m5\u001b[39m]])\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:1151\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[1;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1144\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[0;32m   1146\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m   1147\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m   1148\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m   1149\u001b[0m     )\n\u001b[0;32m   1150\u001b[0m ):\n\u001b[1;32m-> 1151\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fit_method(estimator, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:898\u001b[0m, in \u001b[0;36mBaseSearchCV.fit\u001b[1;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[0;32m    892\u001b[0m     results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_format_results(\n\u001b[0;32m    893\u001b[0m         all_candidate_params, n_splits, all_out, all_more_results\n\u001b[0;32m    894\u001b[0m     )\n\u001b[0;32m    896\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m results\n\u001b[1;32m--> 898\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_run_search(evaluate_candidates)\n\u001b[0;32m    900\u001b[0m \u001b[38;5;66;03m# multimetric is determined here because in the case of a callable\u001b[39;00m\n\u001b[0;32m    901\u001b[0m \u001b[38;5;66;03m# self.scoring the return type is only known after calling\u001b[39;00m\n\u001b[0;32m    902\u001b[0m first_test_score \u001b[38;5;241m=\u001b[39m all_out[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest_scores\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:1419\u001b[0m, in \u001b[0;36mGridSearchCV._run_search\u001b[1;34m(self, evaluate_candidates)\u001b[0m\n\u001b[0;32m   1417\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_run_search\u001b[39m(\u001b[38;5;28mself\u001b[39m, evaluate_candidates):\n\u001b[0;32m   1418\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Search all candidates in param_grid\"\"\"\u001b[39;00m\n\u001b[1;32m-> 1419\u001b[0m     evaluate_candidates(ParameterGrid(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparam_grid))\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:845\u001b[0m, in \u001b[0;36mBaseSearchCV.fit.<locals>.evaluate_candidates\u001b[1;34m(candidate_params, cv, more_results)\u001b[0m\n\u001b[0;32m    837\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mverbose \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m    838\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\n\u001b[0;32m    839\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFitting \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;124m folds for each of \u001b[39m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;124m candidates,\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    840\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m totalling \u001b[39m\u001b[38;5;132;01m{2}\u001b[39;00m\u001b[38;5;124m fits\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[0;32m    841\u001b[0m             n_splits, n_candidates, n_candidates \u001b[38;5;241m*\u001b[39m n_splits\n\u001b[0;32m    842\u001b[0m         )\n\u001b[0;32m    843\u001b[0m     )\n\u001b[1;32m--> 845\u001b[0m out \u001b[38;5;241m=\u001b[39m parallel(\n\u001b[0;32m    846\u001b[0m     delayed(_fit_and_score)(\n\u001b[0;32m    847\u001b[0m         clone(base_estimator),\n\u001b[0;32m    848\u001b[0m         X,\n\u001b[0;32m    849\u001b[0m         y,\n\u001b[0;32m    850\u001b[0m         train\u001b[38;5;241m=\u001b[39mtrain,\n\u001b[0;32m    851\u001b[0m         test\u001b[38;5;241m=\u001b[39mtest,\n\u001b[0;32m    852\u001b[0m         parameters\u001b[38;5;241m=\u001b[39mparameters,\n\u001b[0;32m    853\u001b[0m         split_progress\u001b[38;5;241m=\u001b[39m(split_idx, n_splits),\n\u001b[0;32m    854\u001b[0m         candidate_progress\u001b[38;5;241m=\u001b[39m(cand_idx, n_candidates),\n\u001b[0;32m    855\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_and_score_kwargs,\n\u001b[0;32m    856\u001b[0m     )\n\u001b[0;32m    857\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m (cand_idx, parameters), (split_idx, (train, test)) \u001b[38;5;129;01min\u001b[39;00m product(\n\u001b[0;32m    858\u001b[0m         \u001b[38;5;28menumerate\u001b[39m(candidate_params), \u001b[38;5;28menumerate\u001b[39m(cv\u001b[38;5;241m.\u001b[39msplit(X, y, groups))\n\u001b[0;32m    859\u001b[0m     )\n\u001b[0;32m    860\u001b[0m )\n\u001b[0;32m    862\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(out) \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m    863\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    864\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo fits were performed. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    865\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWas the CV iterator empty? \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    866\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWere there no candidates?\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    867\u001b[0m     )\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\parallel.py:65\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m     60\u001b[0m config \u001b[38;5;241m=\u001b[39m get_config()\n\u001b[0;32m     61\u001b[0m iterable_with_config \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m     62\u001b[0m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[0;32m     63\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m delayed_func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m iterable\n\u001b[0;32m     64\u001b[0m )\n\u001b[1;32m---> 65\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__call__\u001b[39m(iterable_with_config)\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\Lib\\site-packages\\joblib\\parallel.py:1085\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1076\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1077\u001b[0m     \u001b[38;5;66;03m# Only set self._iterating to True if at least a batch\u001b[39;00m\n\u001b[0;32m   1078\u001b[0m     \u001b[38;5;66;03m# was dispatched. In particular this covers the edge\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1082\u001b[0m     \u001b[38;5;66;03m# was very quick and its callback already dispatched all the\u001b[39;00m\n\u001b[0;32m   1083\u001b[0m     \u001b[38;5;66;03m# remaining jobs.\u001b[39;00m\n\u001b[0;32m   1084\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_iterating \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m-> 1085\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdispatch_one_batch(iterator):\n\u001b[0;32m   1086\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_iterating \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_original_iterator \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1088\u001b[0m     \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdispatch_one_batch(iterator):\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\Lib\\site-packages\\joblib\\parallel.py:901\u001b[0m, in \u001b[0;36mParallel.dispatch_one_batch\u001b[1;34m(self, iterator)\u001b[0m\n\u001b[0;32m    899\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m    900\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 901\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dispatch(tasks)\n\u001b[0;32m    902\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\Lib\\site-packages\\joblib\\parallel.py:819\u001b[0m, in \u001b[0;36mParallel._dispatch\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    817\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[0;32m    818\u001b[0m     job_idx \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jobs)\n\u001b[1;32m--> 819\u001b[0m     job \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend\u001b[38;5;241m.\u001b[39mapply_async(batch, callback\u001b[38;5;241m=\u001b[39mcb)\n\u001b[0;32m    820\u001b[0m     \u001b[38;5;66;03m# A job can complete so quickly than its callback is\u001b[39;00m\n\u001b[0;32m    821\u001b[0m     \u001b[38;5;66;03m# called before we get here, causing self._jobs to\u001b[39;00m\n\u001b[0;32m    822\u001b[0m     \u001b[38;5;66;03m# grow. To ensure correct results ordering, .insert is\u001b[39;00m\n\u001b[0;32m    823\u001b[0m     \u001b[38;5;66;03m# used (rather than .append) in the following line\u001b[39;00m\n\u001b[0;32m    824\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jobs\u001b[38;5;241m.\u001b[39minsert(job_idx, job)\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\Lib\\site-packages\\joblib\\_parallel_backends.py:208\u001b[0m, in \u001b[0;36mSequentialBackend.apply_async\u001b[1;34m(self, func, callback)\u001b[0m\n\u001b[0;32m    206\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mapply_async\u001b[39m(\u001b[38;5;28mself\u001b[39m, func, callback\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m    207\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Schedule a func to be run\"\"\"\u001b[39;00m\n\u001b[1;32m--> 208\u001b[0m     result \u001b[38;5;241m=\u001b[39m ImmediateResult(func)\n\u001b[0;32m    209\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m callback:\n\u001b[0;32m    210\u001b[0m         callback(result)\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\Lib\\site-packages\\joblib\\_parallel_backends.py:597\u001b[0m, in \u001b[0;36mImmediateResult.__init__\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    594\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, batch):\n\u001b[0;32m    595\u001b[0m     \u001b[38;5;66;03m# Don't delay the application, to avoid keeping the input\u001b[39;00m\n\u001b[0;32m    596\u001b[0m     \u001b[38;5;66;03m# arguments in memory\u001b[39;00m\n\u001b[1;32m--> 597\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mresults \u001b[38;5;241m=\u001b[39m batch()\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\Lib\\site-packages\\joblib\\parallel.py:288\u001b[0m, in \u001b[0;36mBatchedCalls.__call__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    284\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    285\u001b[0m     \u001b[38;5;66;03m# Set the default nested backend to self._backend but do not set the\u001b[39;00m\n\u001b[0;32m    286\u001b[0m     \u001b[38;5;66;03m# change the default number of processes to -1\u001b[39;00m\n\u001b[0;32m    287\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m parallel_backend(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend, n_jobs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_n_jobs):\n\u001b[1;32m--> 288\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m [func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    289\u001b[0m                 \u001b[38;5;28;01mfor\u001b[39;00m func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mitems]\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\Lib\\site-packages\\joblib\\parallel.py:288\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    284\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    285\u001b[0m     \u001b[38;5;66;03m# Set the default nested backend to self._backend but do not set the\u001b[39;00m\n\u001b[0;32m    286\u001b[0m     \u001b[38;5;66;03m# change the default number of processes to -1\u001b[39;00m\n\u001b[0;32m    287\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m parallel_backend(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend, n_jobs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_n_jobs):\n\u001b[1;32m--> 288\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m [func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    289\u001b[0m                 \u001b[38;5;28;01mfor\u001b[39;00m func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mitems]\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\parallel.py:127\u001b[0m, in \u001b[0;36m_FuncWrapper.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    125\u001b[0m     config \u001b[38;5;241m=\u001b[39m {}\n\u001b[0;32m    126\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mconfig):\n\u001b[1;32m--> 127\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunction(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:720\u001b[0m, in \u001b[0;36m_fit_and_score\u001b[1;34m(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, return_train_score, return_parameters, return_n_test_samples, return_times, return_estimator, split_progress, candidate_progress, error_score)\u001b[0m\n\u001b[0;32m    717\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m parameters\u001b[38;5;241m.\u001b[39mitems():\n\u001b[0;32m    718\u001b[0m         cloned_parameters[k] \u001b[38;5;241m=\u001b[39m clone(v, safe\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m--> 720\u001b[0m     estimator \u001b[38;5;241m=\u001b[39m estimator\u001b[38;5;241m.\u001b[39mset_params(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mcloned_parameters)\n\u001b[0;32m    722\u001b[0m start_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[0;32m    724\u001b[0m X_train, y_train \u001b[38;5;241m=\u001b[39m _safe_split(estimator, X, y, train)\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:229\u001b[0m, in \u001b[0;36mBaseEstimator.set_params\u001b[1;34m(self, **params)\u001b[0m\n\u001b[0;32m    227\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m key \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m valid_params:\n\u001b[0;32m    228\u001b[0m     local_valid_params \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_param_names()\n\u001b[1;32m--> 229\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    230\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInvalid parameter \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkey\u001b[38;5;132;01m!r}\u001b[39;00m\u001b[38;5;124m for estimator \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    231\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mValid parameters are: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mlocal_valid_params\u001b[38;5;132;01m!r}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    232\u001b[0m     )\n\u001b[0;32m    234\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m delim:\n\u001b[0;32m    235\u001b[0m     nested_params[key][sub_key] \u001b[38;5;241m=\u001b[39m value\n",
      "\u001b[1;31mValueError\u001b[0m: Invalid parameter 'optimizer' for estimator MLPRegressor(hidden_layer_sizes=(32,), max_iter=50). Valid parameters are: ['activation', 'alpha', 'batch_size', 'beta_1', 'beta_2', 'early_stopping', 'epsilon', 'hidden_layer_sizes', 'learning_rate', 'learning_rate_init', 'max_fun', 'max_iter', 'momentum', 'n_iter_no_change', 'nesterovs_momentum', 'power_t', 'random_state', 'shuffle', 'solver', 'tol', 'validation_fraction', 'verbose', 'warm_start']."
     ]
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Define hyperparameter grid\n",
    "param_grid = {\n",
    "    'hidden_layer_sizes': [(32,), (64,), (32, 32)],\n",
    "    'activation': ['relu', 'tanh'],\n",
    "    'optimizer': ['adam', 'sgd'],\n",
    "    'max_iter': [50, 100, 150],  # 'epochs' is replaced by 'max_iter' for MLPRegressor\n",
    "}\n",
    "\n",
    "# Example usage\n",
    "nn_model = MLPRegressor()\n",
    "grid_search = GridSearchCV(nn_model, param_grid, cv=3)\n",
    "grid_search.fit(x_data.reshape(-1, 1), y_data)\n",
    "\n",
    "best_model = grid_search.best_estimator_\n",
    "result_tuned = best_model.predict([[5]])\n",
    "print(result_tuned)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d40a835",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
