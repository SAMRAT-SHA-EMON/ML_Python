{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "903ec21a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\MONIRUL ISLAM\\AppData\\Roaming\\Python\\Python311\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n",
      "Index(['Unnamed: 0', 'user_id', 'R', 'F', 'M'], dtype='object')\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "could not convert string to float: 'Os2EMFl6xzeTwPk4'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 28\u001b[0m\n\u001b[0;32m     26\u001b[0m \u001b[38;5;66;03m# Linear Regression in Numerical Analysis\u001b[39;00m\n\u001b[0;32m     27\u001b[0m model_lr \u001b[38;5;241m=\u001b[39m LinearRegression()\n\u001b[1;32m---> 28\u001b[0m model_lr\u001b[38;5;241m.\u001b[39mfit(X_train, y_train)\n\u001b[0;32m     29\u001b[0m y_pred_lr \u001b[38;5;241m=\u001b[39m model_lr\u001b[38;5;241m.\u001b[39mpredict(X_test)\n\u001b[0;32m     30\u001b[0m mse_lr \u001b[38;5;241m=\u001b[39m mean_squared_error(y_test, y_pred_lr)\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:1151\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[1;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1144\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[0;32m   1146\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m   1147\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m   1148\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m   1149\u001b[0m     )\n\u001b[0;32m   1150\u001b[0m ):\n\u001b[1;32m-> 1151\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fit_method(estimator, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_base.py:678\u001b[0m, in \u001b[0;36mLinearRegression.fit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    674\u001b[0m n_jobs_ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_jobs\n\u001b[0;32m    676\u001b[0m accept_sparse \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpositive \u001b[38;5;28;01melse\u001b[39;00m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcsr\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcsc\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcoo\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m--> 678\u001b[0m X, y \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_data(\n\u001b[0;32m    679\u001b[0m     X, y, accept_sparse\u001b[38;5;241m=\u001b[39maccept_sparse, y_numeric\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, multi_output\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m    680\u001b[0m )\n\u001b[0;32m    682\u001b[0m has_sw \u001b[38;5;241m=\u001b[39m sample_weight \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    683\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_sw:\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:621\u001b[0m, in \u001b[0;36mBaseEstimator._validate_data\u001b[1;34m(self, X, y, reset, validate_separately, cast_to_ndarray, **check_params)\u001b[0m\n\u001b[0;32m    619\u001b[0m         y \u001b[38;5;241m=\u001b[39m check_array(y, input_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124my\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mcheck_y_params)\n\u001b[0;32m    620\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 621\u001b[0m         X, y \u001b[38;5;241m=\u001b[39m check_X_y(X, y, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mcheck_params)\n\u001b[0;32m    622\u001b[0m     out \u001b[38;5;241m=\u001b[39m X, y\n\u001b[0;32m    624\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m no_val_X \u001b[38;5;129;01mand\u001b[39;00m check_params\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mensure_2d\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mTrue\u001b[39;00m):\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\validation.py:1163\u001b[0m, in \u001b[0;36mcheck_X_y\u001b[1;34m(X, y, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, estimator)\u001b[0m\n\u001b[0;32m   1143\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m   1144\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mestimator_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m requires y to be passed, but the target y is None\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1145\u001b[0m     )\n\u001b[0;32m   1147\u001b[0m X \u001b[38;5;241m=\u001b[39m check_array(\n\u001b[0;32m   1148\u001b[0m     X,\n\u001b[0;32m   1149\u001b[0m     accept_sparse\u001b[38;5;241m=\u001b[39maccept_sparse,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1160\u001b[0m     input_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mX\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   1161\u001b[0m )\n\u001b[1;32m-> 1163\u001b[0m y \u001b[38;5;241m=\u001b[39m _check_y(y, multi_output\u001b[38;5;241m=\u001b[39mmulti_output, y_numeric\u001b[38;5;241m=\u001b[39my_numeric, estimator\u001b[38;5;241m=\u001b[39mestimator)\n\u001b[0;32m   1165\u001b[0m check_consistent_length(X, y)\n\u001b[0;32m   1167\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m X, y\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\validation.py:1188\u001b[0m, in \u001b[0;36m_check_y\u001b[1;34m(y, multi_output, y_numeric, estimator)\u001b[0m\n\u001b[0;32m   1186\u001b[0m     _ensure_no_complex_data(y)\n\u001b[0;32m   1187\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m y_numeric \u001b[38;5;129;01mand\u001b[39;00m y\u001b[38;5;241m.\u001b[39mdtype\u001b[38;5;241m.\u001b[39mkind \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mO\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m-> 1188\u001b[0m     y \u001b[38;5;241m=\u001b[39m y\u001b[38;5;241m.\u001b[39mastype(np\u001b[38;5;241m.\u001b[39mfloat64)\n\u001b[0;32m   1190\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m y\n",
      "\u001b[1;31mValueError\u001b[0m: could not convert string to float: 'Os2EMFl6xzeTwPk4'"
     ]
    }
   ],
   "source": [
    "# Import necessary libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from scipy.interpolate import interp1d\n",
    "from sklearn.svm import SVR\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "\n",
    "# Load your dataset (replace 'your_dataset.csv' with your actual dataset)\n",
    "data = pd.read_csv('RFM.csv')\n",
    "\n",
    "# Check the column names in your dataset\n",
    "print(data.columns)\n",
    "\n",
    "# Replace 'feature1', 'feature2', 'target' with your actual column names\n",
    "X = data[['R', 'F']]\n",
    "y = data['user_id']\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Linear Regression in Numerical Analysis\n",
    "model_lr = LinearRegression()\n",
    "model_lr.fit(X_train, y_train)\n",
    "y_pred_lr = model_lr.predict(X_test)\n",
    "mse_lr = mean_squared_error(y_test, y_pred_lr)\n",
    "\n",
    "# Newton Interpolation Method\n",
    "x = np.array([1, 2, 3, 4, 5])\n",
    "y = np.array([2, 4, 1, 3, 7])\n",
    "newton_interp = interp1d(x, y, kind='cubic')\n",
    "x_interp = np.linspace(1, 5, 100)\n",
    "y_interp = newton_interp(x_interp)\n",
    "\n",
    "# Support Vector Machines (SVM) in Numerical Analysis\n",
    "svr_rbf = SVR(kernel='rbf', C=100, gamma=0.1, epsilon=0.1)\n",
    "svr_rbf.fit(X, y)\n",
    "X_plot = np.linspace(0, 5, 100)[:, np.newaxis]\n",
    "y_pred_svm = svr_rbf.predict(X_plot)\n",
    "\n",
    "# Neural Networks for Numerical Analysis\n",
    "model_nn = Sequential()\n",
    "model_nn.add(Dense(1, input_dim=1, activation='linear'))\n",
    "model_nn.compile(optimizer='sgd', loss='mean_squared_error')\n",
    "model_nn.fit(X, y, epochs=50, batch_size=10, verbose=0)\n",
    "y_pred_nn = model_nn.predict(X)\n",
    "\n",
    "# Visualization\n",
    "fig, axes = plt.subplots(nrows=2, ncols=2, figsize=(15, 10))\n",
    "\n",
    "# Linear Regression Visualization\n",
    "axes[0, 0].scatter(X_test.iloc[:, 0], y_test, color='black')\n",
    "axes[0, 0].plot(X_test.iloc[:, 0], y_pred_lr, color='blue', linewidth=3)\n",
    "axes[0, 0].set_title('Linear Regression: Feature1 vs. Target')\n",
    "axes[0, 0].set_xlabel('Feature1')\n",
    "axes[0, 0].set_ylabel('Target')\n",
    "\n",
    "# Newton Interpolation Visualization\n",
    "axes[0, 1].scatter(x, y, label='Original Data')\n",
    "axes[0, 1].plot(x_interp, y_interp, label='Newton Interpolation', color='red')\n",
    "axes[0, 1].set_title('Newton Interpolation Example')\n",
    "axes[0, 1].set_xlabel('X')\n",
    "axes[0, 1].set_ylabel('Y')\n",
    "axes[0, 1].legend()\n",
    "\n",
    "# SVM Visualization\n",
    "axes[1, 0].scatter(X, y, color='black', label='Data')\n",
    "axes[1, 0].plot(X_plot, y_pred_svm, color='red', label='RBF Kernel SVM')\n",
    "axes[1, 0].set_title('Support Vector Machines (SVM) Example')\n",
    "axes[1, 0].set_xlabel('X')\n",
    "axes[1, 0].set_ylabel('Y')\n",
    "axes[1, 0].legend()\n",
    "\n",
    "# Neural Network Visualization\n",
    "axes[1, 1].scatter(X, y, label='Actual Data')\n",
    "axes[1, 1].plot(X, y_pred_nn, color='red', label='Neural Network Prediction')\n",
    "axes[1, 1].set_title('Neural Networks Example for Regression')\n",
    "axes[1, 1].set_xlabel('X')\n",
    "axes[1, 1].set_ylabel('Y')\n",
    "axes[1, 1].legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Print Mean Squared Error for Linear Regression\n",
    "print(f'Mean Squared Error (Linear Regression): {mse_lr}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6aa13ce9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
